<article>
  <h1>Web Protocols Cheat Sheet &#8211; Frontend System Design</h1>
  <p>
    <img
      loading="lazy"
      decoding="async"
      class="alignnone wp-image-1434 size-full"
      style="max-width: 200px"
      src="https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.15.59-PM.png"
      alt=""
      width="698"
      height="1338"
      srcset="
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.15.59-PM.png          698w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.15.59-PM-157x300.png  157w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.15.59-PM-534x1024.png 534w
      "
      sizes="(max-width: 698px) 100vw, 698px"
    />
  </p>
  <p>
    HTTP/1.x and HTTP/2 represent two major versions of the Hypertext Transfer
    Protocol used for the World Wide Web. HTTP/1.x, with its final iteration
    being HTTP/1.1, has been the backbone of the web for decades. Its simplicity
    and text-based nature characterize it, making it easy to use and understand.
    Each request-response cycle in HTTP/1.x typically opens a new TCP
    connection, leading to a straightforward but potentially inefficient
    process, especially when loading complex web pages with many elements.
  </p>
  <p>
    HTTP/2, on the other hand, introduced several key improvements to enhance
    web performance and efficiency. One of the most significant changes is the
    introduction of multiplexing, allowing multiple requests and responses to be
    sent asynchronously over a single TCP connection, reducing latency and
    improving page load times. HTTP/2 also incorporates header compression to
    reduce overhead and introduces server push, which allows servers to send
    resources proactively. Despite these advancements, HTTP/2 maintains
    high-level compatibility with HTTP/1.x, ensuring that applications built on
    the older versions can be upgraded without drastic changes.
  </p>
  <table border="1">
    <thead>
      <tr>
        <th>Feature</th>
        <th>HTTP/1.x Pros</th>
        <th>HTTP/2 Pros</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Connection Management</td>
        <td>
          Simple; each request/response pair uses a separate TCP connection.
        </td>
        <td>
          Multiple requests and responses can be multiplexed over a single TCP
          connection, reducing overhead.
        </td>
      </tr>
      <tr>
        <td>Performance</td>
        <td>
          Well-understood behavior and widespread support across web
          infrastructure.
        </td>
        <td>
          Significantly improved performance through header compression,
          prioritization of requests, and server push capabilities.
        </td>
      </tr>
      <tr>
        <td>Resource Loading</td>
        <td>
          Sequential loading can be simpler for developers to manage and
          predict.
        </td>
        <td>
          Concurrent loading of resources reduces page load times and improves
          user experience.
        </td>
      </tr>
      <tr>
        <td>Protocol Overhead</td>
        <td>
          HTTP/1.x&#8217;s textual nature can be more readable and easier to
          debug manually.
        </td>
        <td>
          Binary framing layer reduces overhead and improves parsing efficiency.
        </td>
      </tr>
      <tr>
        <td>Scalability</td>
        <td>
          More straightforward to implement on small-scale or less complex
          websites.
        </td>
        <td>
          Better suited for complex applications and high-traffic websites due
          to efficient use of resources.
        </td>
      </tr>
      <tr>
        <td>Compatibility and Adoption</td>
        <td>Universal support across all web browsers and servers.</td>
        <td>
          It requires modern web infrastructure and browsers but is widely
          supported in current environments.
        </td>
      </tr>
    </tbody>
  </table>
  <h2>Polling</h2>
  <p>
    <img
      loading="lazy"
      decoding="async"
      class="alignnone size-full wp-image-1439"
      style="max-width: 200px"
      src="https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM.png"
      alt=""
      width="1148"
      height="1188"
      srcset="
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM.png          1148w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM-290x300.png   290w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM-990x1024.png  990w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM-768x795.png   768w
      "
      sizes="(max-width: 1148px) 100vw, 1148px"
    />
  </p>
  <p>
    Polling, a technique used in computer networks to periodically check the
    state or presence of new data by making repeated requests to a server, is
    revered for its implementation simplicity. It&#8217;s straightforward to set
    up, making it a go-to choice for many developers when real-time data updates
    are not critical. Polling facilitates easy load balancing, distributing
    requests across multiple servers to enhance scalability. Additionally,
    it&#8217;s compatible with modern protocols like HTTP/2, which can optimize
    its performance through features like multiplexing.
  </p>
  <p>
    However, polling is not without its drawbacks. It can lead to inefficient
    use of resources, particularly if new data is infrequent, as servers must
    process requests even when there&#8217;s nothing new to return. This can
    also result in increased server load, affecting overall performance, and
    generate significant network traffic, leading to bandwidth overuse.
    Moreover, the inherent nature of polling means data is not updated in real
    time, which can result in noticeable delays in data freshness, potentially
    impacting user experience in applications where timely data is crucial.
  </p>
  <table border="1">
    <thead>
      <tr>
        <th>Feature</th>
        <th>Pros</th>
        <th>Cons</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Implementation Simplicity</td>
        <td>
          Polling is straightforward to implement, involving periodic requests
          to the server.
        </td>
        <td>Can lead to inefficient resource use if new data is infrequent.</td>
      </tr>
      <tr>
        <td>Load Balancing</td>
        <td>
          Distributing requests across multiple servers is relatively simple,
          enhancing scalability.
        </td>
        <td>Server resources may be underutilized during off-peak times.</td>
      </tr>
      <tr>
        <td>Protocol Compatibility</td>
        <td>
          Works well with HTTP/2, leveraging its performance optimizations and
          multiplexing capabilities.
        </td>
        <td>
          Without careful implementation, can negate HTTP/2 benefits due to
          frequent connections.
        </td>
      </tr>
      <tr>
        <td>Data Freshness</td>
        <td>Periodic updates ensure data is regularly refreshed.</td>
        <td>
          May experience delays in receiving real-time data due to fixed
          interval polling.
        </td>
      </tr>
      <tr>
        <td>Server Load</td>
        <td>
          Server load can be predicted and managed based on known polling
          intervals.
        </td>
        <td>
          Constant polling can lead to unnecessary server load, impacting
          performance.
        </td>
      </tr>
      <tr>
        <td>Network Traffic</td>
        <td>Simple to monitor and predict network traffic patterns.</td>
        <td>
          Generates significant overhead, especially when there&#8217;s no new
          data to retrieve.
        </td>
      </tr>
    </tbody>
  </table>
  <h2>Long Polling</h2>
  <p>
    While inheriting many advantages of traditional polling, such as ease of
    implementation and compatibility with existing web infrastructures, this
    approach offers a more efficient data retrieval method. Adopting a model
    that allows the server to hold a request open until new data is available
    can reduce the overall number of requests, potentially decreasing
    unnecessary network traffic and improving the freshness of the data
    presented to the user.
  </p>
  <p>
    However, this method is not without its drawbacks. Similar to traditional
    polling, it can still suffer from issues like long latency in data updates,
    which may not be ideal for applications requiring real-time responsiveness.
    Connection timeouts and the risk of increased traffic overhead during peak
    times or in scenarios with numerous concurrent connections also pose
    significant challenges. Thus, while this method can offer improvements in
    certain areas over traditional polling, careful consideration and management
    are required to mitigate its limitations, especially in high-demand
    environments.
  </p>
  <table border="1">
    <thead>
      <tr>
        <th>Aspect</th>
        <th>Pros</th>
        <th>Cons</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Implementation Ease</td>
        <td>
          Shares the simplicity of setup and debugging with traditional polling.
        </td>
        <td>
          Additional logic may be required to handle long polling connections
          and responses.
        </td>
      </tr>
      <tr>
        <td>Infrastructure Compatibility</td>
        <td>
          Utilizes existing infrastructure without needing significant changes.
        </td>
        <td>
          Limited by the capabilities and scalability of the current
          infrastructure.
        </td>
      </tr>
      <tr>
        <td>Data Freshness</td>
        <td>
          Improves over traditional polling by reducing the wait time for new
          data.
        </td>
        <td>
          Still subject to delays, not suitable for real-time applications
          needing instant updates.
        </td>
      </tr>
      <tr>
        <td>Resource Efficiency</td>
        <td>
          Can be optimized to reduce unnecessary network load compared to
          constant polling.
        </td>
        <td>
          Potential for increased server and network load during peak usage or
          with many clients.
        </td>
      </tr>
      <tr>
        <td>User Experience</td>
        <td>Can improve user experience by providing more timely updates.</td>
        <td>
          Long wait times for updates can still negatively impact user
          engagement.
        </td>
      </tr>
      <tr>
        <td>Scalability</td>
        <td>More scalable than traditional polling in moderate use cases.</td>
        <td>
          Scalability challenges can arise with a high number of concurrent long
          polling requests.
        </td>
      </tr>
    </tbody>
  </table>
  <h2>WebSockets</h2>
  <p>
    <img
      loading="lazy"
      decoding="async"
      class="alignnone size-full wp-image-1440"
      style="max-width: 200px"
      src="https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.23-PM.png"
      alt=""
      width="802"
      height="1200"
      srcset="
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.23-PM.png          802w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.23-PM-201x300.png  201w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.23-PM-684x1024.png 684w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.23-PM-768x1149.png 768w
      "
      sizes="(max-width: 802px) 100vw, 802px"
    />
  </p>
  <table border="1">
    <thead>
      <tr>
        <th>Aspect</th>
        <th>Pros</th>
        <th>Cons</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Communication Type</td>
        <td>
          Duplex communication allows for real-time, bidirectional data exchange
          between client and server.
        </td>
        <td></td>
      </tr>
      <tr>
        <td>Performance</td>
        <td>
          High-speed communication channel, ideal for low-latency applications.
        </td>
        <td>
          Continuous connections can increase resource consumption on both the
          client and server sides.
        </td>
      </tr>
      <tr>
        <td>Connection Efficiency</td>
        <td>
          Utilizes a single TCP connection, reducing the overhead of multiple
          HTTP connections.
        </td>
        <td>
          Managing a single, persistent connection can be complex, especially in
          distributed systems.
        </td>
      </tr>
      <tr>
        <td>Scalability</td>
        <td></td>
        <td>
          Challenges in efficiently load-balancing WebSocket connections can
          affect scalability.
        </td>
      </tr>
      <tr>
        <td>Compatibility</td>
        <td>
          Supported by most modern web browsers, facilitating widespread use.
        </td>
        <td>
          Some firewalls, proxies, and older network infrastructure may face
          compatibility issues.
        </td>
      </tr>
      <tr>
        <td>Protocol Overhead</td>
        <td>
          Lower protocol overhead compared to HTTP polling, enhancing
          efficiency.
        </td>
        <td>
          Initial handshake and setup can introduce some overhead and
          complexity.
        </td>
      </tr>
    </tbody>
  </table>
  <h2>Server-Sent Events (SSE)</h2>
  <p>
    <img
      loading="lazy"
      decoding="async"
      class="alignnone size-full wp-image-1441"
      style="max-width: 200px"
      src="https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.38-PM.png"
      alt=""
      width="962"
      height="1186"
      srcset="
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.38-PM.png          962w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.38-PM-243x300.png  243w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.38-PM-831x1024.png 831w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.19.38-PM-768x947.png  768w
      "
      sizes="(max-width: 962px) 100vw, 962px"
    />
  </p>
  <p>
    Server-sent events (SSE) offer a streamlined method for servers to push
    updates to web clients, harnessing the capabilities of HTTP/2 for improved
    efficiency and performance. Using gzipping and multiplexing, inherent to
    HTTP/2, enables SSE to deliver updates with reduced bandwidth usage and
    better connection management. This approach is particularly
    resource-efficient as it transmits only necessary text-based updates, making
    it an ideal choice for applications that require server-initiated messages,
    such as live news feeds or stock tickers.
  </p>
  <p>
    However, the primary limitation of SSE lies in its unidirectional nature,
    allowing data to flow solely from server to client. This makes it less
    suited for applications that require a two-way exchange of information, such
    as interactive games or chat applications. Furthermore, its focus on text
    data may restrict its use in scenarios that demand the transmission of
    binary data or complex data structures. Despite these constraints,
    SSE&#8217;s ease of integration with
  </p>
  <table border="1">
    <thead>
      <tr>
        <th>Aspect</th>
        <th>Pros</th>
        <th>Cons</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Protocol Advantages</td>
        <td>
          Benefits from HTTP/2 improvements like gzipping for reduced size and
          multiplexing for better connection efficiency.
        </td>
        <td></td>
      </tr>
      <tr>
        <td>Resource Utilization</td>
        <td>
          Sends only necessary updates as text, optimizing bandwidth and server
          resources.
        </td>
        <td></td>
      </tr>
      <tr>
        <td>Scalability</td>
        <td>
          Compatible with standard load balancing strategies, enhancing
          scalability.
        </td>
        <td></td>
      </tr>
      <tr>
        <td>Communication Direction</td>
        <td></td>
        <td>
          Limited to server-to-client communication, not supporting
          client-initiated data streams.
        </td>
      </tr>
      <tr>
        <td>Data Flexibility</td>
        <td></td>
        <td>
          Primarily supports text-based data, which may not be ideal for binary
          or more complex data needs.
        </td>
      </tr>
      <tr>
        <td>Integration Simplicity</td>
        <td>
          More straightforward to implement on top of the existing HTTP
          infrastructure without significant changes.
        </td>
        <td></td>
      </tr>
      <tr>
        <td>Real-Time Capability</td>
        <td>
          Provides near real-time updates to clients, enhancing user experience
          for live data feeds.
        </td>
        <td>
          May experience latency issues in high-volume or high-traffic
          scenarios.
        </td>
      </tr>
    </tbody>
  </table>
  <h2>REST API</h2>
  <p>
    <img
      loading="lazy"
      decoding="async"
      class="alignnone size-full wp-image-1442"
      style="max-width: 200px"
      src="https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM-1.png"
      alt=""
      width="1148"
      height="1188"
      srcset="
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM-1.png          1148w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM-1-290x300.png   290w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM-1-990x1024.png  990w,
        https://api.frontendlead.com/wp-content/uploads/2024/03/Screenshot-2025-01-01-at-1.18.40-PM-1-768x795.png   768w
      "
      sizes="(max-width: 1148px) 100vw, 1148px"
    />
  </p>
  <div>
    <p>
      REST APIs have long been the standard for web services, prized for their
      simplicity, standardization, and compatibility with web technologies like
      HTTP/2. They excel in scenarios where the API&#8217;s structure and data
      requirements are relatively stable and predictable, offering
      straightforward scalability through load balancing. However, their
      stateless nature can introduce latency in dynamic environments, and the
      granularity of data retrieval may result in traffic inefficiencies.
    </p>
    <p>
      On the other hand, GraphQL represents a modern approach to API design,
      emphasizing flexibility and efficiency in data retrieval. By allowing
      clients to specify precisely what data they need, GraphQL can
      significantly reduce over-fetching, making it an attractive choice for
      dynamic, data-driven applications. Its type system and caching
      capabilities further enhance performance and reliability. However, the
      complexity of queries and potential verbosity pose challenges,
      particularly regarding traffic overhead and server processing demands.
    </p>
  </div>
  <table border="1">
    <thead>
      <tr>
        <th>Aspect</th>
        <th>GraphQL Pros</th>
        <th>GraphQL Cons</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>API Design</td>
        <td>
          Enables clients to request what they need, reducing overfetching
          precisely.
        </td>
        <td></td>
      </tr>
      <tr>
        <td>Type Safety</td>
        <td>
          The strongly typed nature of GraphQL enhances API safety and reduces
          client-side errors.
        </td>
        <td></td>
      </tr>
      <tr>
        <td>Caching</td>
        <td>
          Advanced caching capabilities at the client level improve application
          performance.
        </td>
        <td></td>
      </tr>
      <tr>
        <td>Latency</td>
        <td></td>
        <td>
          Depending on the server&#8217;s processing capabilities, complex
          queries can result in latency.
        </td>
      </tr>
      <tr>
        <td>Connection Reliability</td>
        <td></td>
        <td>Connection timeouts may occur, similar to REST APIs.</td>
      </tr>
      <tr>
        <td>Verbosity</td>
        <td></td>
        <td>
          Verbose queries can lead to increased traffic, especially with nested
          structures.
        </td>
      </tr>
    </tbody>
  </table>
  <p>&nbsp;</p>
</article>
